{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31826,
     "status": "ok",
     "timestamp": 1568569171276,
     "user": {
      "displayName": "Софья Федоровна Якушева",
      "photoUrl": "",
      "userId": "11846467870731418335"
     },
     "user_tz": -180
    },
    "id": "3RbEyxVP87aS",
    "outputId": "0058ec85-401f-46c7-8b92-50c8dbb52d70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n",
      "Collecting tensorboardX\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/12/dcaf67e1312475b26db9e45e7bb6f32b540671a9ee120b3a72d9e09bc517/tensorboardX-1.8-py2.py3-none-any.whl (216kB)\n",
      "\u001b[K     |████████████████████████████████| 225kB 2.8MB/s \n",
      "\u001b[?25hRequirement already satisfied: protobuf>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (3.7.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.16.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX) (1.12.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.2.0->tensorboardX) (41.2.0)\n",
      "Installing collected packages: tensorboardX\n",
      "Successfully installed tensorboardX-1.8\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "! pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "paJV54AZF8r1"
   },
   "source": [
    "## Данные\n",
    "\n",
    "Был проведён визуальный анализ данных, который показал следующее.\n",
    "\n",
    "Обучающая выборка представляет собой набор трёхканальных изображений размера 320x240 количеством около тысячи, что очень мало для решения подобного рода задач. На большинстве из них запечатлены только лица людей, но присутствуют также фотографии человека в полный рост. Почти все фотографии цветные, но встречаются и чёрно-белые. Люди на фотографиях - разных рас, пола, возраста, имеют разное выражение лица и стоят в разных позах.\n",
    "\n",
    "На фотографиях человек занимает большую часть площади, в большинстве случаев - больше половины. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3SmZQlEOGCl1"
   },
   "source": [
    "## Аугментация\n",
    "\n",
    "Поскольку количество данных чрезвычайно мало, для повышения качества модели необходимо использовать аугментацию.\n",
    "\n",
    "В ходе решения были рассмотрены следующие методы:\n",
    "\n",
    "1) отражения относительно горизонтальной и вертикальной осей,\n",
    "\n",
    "2) обрезание с последующим растяжением или сдвигом относительно первоначального положения,\n",
    "\n",
    "3) вращение относительно произвольного центра на произвольное число градусов,\n",
    "\n",
    "4) цветовая аугментация (изменение яркости/контрастности, обмен местами каналов изображения, обращение изображения, изменение яркости каналов, преобразование в чёрно-белое изображение),\n",
    "\n",
    "5) наложение шума "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6uvuyjrMGCrB"
   },
   "source": [
    "## Выбор модели\n",
    "\n",
    "Существует несколько методов решения задачи сегментации.\n",
    "\n",
    "1) patch-based: обучаем сетку классифицировать кусочки изображения как объекты или фон, затем комбинируем ответы для получения итоговой маски\n",
    "\n",
    "2) энкодер: сжимаем, а затем разжимаем изображение, получая на выходе маску (SegNet, Unet)\n",
    "\n",
    "3) алгоритмы компьютерного зрения для распознавания лиц\n",
    "\n",
    "В контексте рассматриваемой задачи наименее трудозатратным методом является использование нейросети-энкодера. Жизненный опыт подсказывал, что лучше Unet ничего не работало... \n",
    "\n",
    "В качестве основной модели использовался Unet, более простая модель энкодера работала хуже. Параметры сети выбирались эмпирически (batch_size, learning_rate и т.д. ). Рассматривались модели с разным количеством фильтров и глубиной. \n",
    "\n",
    "Были рассмотрены различные подходы к аугментации данных. Из применённых методов не слишком эффективными оказались цветовые, а вот вращение и обрезание с последующим растяжением ощутимо улучшили устойчивость модели.\n",
    "\n",
    "Вообще говоря, для решения задачи можно было бы использовать предобученную модель (например, от Google) для сегментации человека, но это было бы нечестно в контексте данного задания."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2095199,
     "status": "ok",
     "timestamp": 1568571662039,
     "user": {
      "displayName": "Софья Федоровна Якушева",
      "photoUrl": "",
      "userId": "11846467870731418335"
     },
     "user_tz": -180
    },
    "id": "mIQzG2Ogo9BE",
    "outputId": "beaa7534-164d-40dd-9fdf-68b47badb5e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current epoch:  0\n",
      "100% 263/263 [06:28<00:00,  1.95s/it]\n",
      "Epoch loss 0.07502820243626947\n",
      "Epoch dice 0.6573579757604269\n",
      "Make test\n",
      "  0% 0/145 [00:00<?, ?it/s]/content/drive/My Drive/laba/train.py:86: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  cur_input = Variable(cur_input, volatile = True)\n",
      "/content/drive/My Drive/laba/train.py:87: UserWarning: volatile was removed and now has no effect. Use `with torch.no_grad():` instead.\n",
      "  cur_target = Variable(cur_target, volatile = True)\n",
      "100% 145/145 [00:39<00:00,  3.65it/s]\n",
      "Test loss 0.32820962338612\n",
      "Test dice 0.6720700833078368\n",
      "Current epoch:  1\n",
      "100% 263/263 [02:17<00:00,  2.35it/s]\n",
      "Epoch loss 0.05418762400916321\n",
      "Epoch dice 0.7443959247694905\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 31.64it/s]\n",
      "Test loss 0.2354416797901022\n",
      "Test dice 0.7651522052860025\n",
      "Current epoch:  2\n",
      "100% 263/263 [02:17<00:00,  2.37it/s]\n",
      "Epoch loss 0.04879469057339679\n",
      "Epoch dice 0.7714197339104552\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 33.62it/s]\n",
      "Test loss 0.23994331195436674\n",
      "Test dice 0.7622082500378067\n",
      "Current epoch:  3\n",
      "100% 263/263 [02:18<00:00,  2.36it/s]\n",
      "Epoch loss 0.04812326277730129\n",
      "Epoch dice 0.7732927990952355\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 31.37it/s]\n",
      "Test loss 0.2374585328430965\n",
      "Test dice 0.7633015834884072\n",
      "Current epoch:  4\n",
      "100% 263/263 [02:19<00:00,  2.32it/s]\n",
      "Epoch loss 0.04446622837519011\n",
      "Epoch dice 0.78959772918773\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 34.64it/s]\n",
      "Test loss 0.22870243417805639\n",
      "Test dice 0.7715327102923561\n",
      "Current epoch:  5\n",
      "100% 263/263 [02:19<00:00,  2.39it/s]\n",
      "Epoch loss 0.04512702884442906\n",
      "Epoch dice 0.7845489037281934\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 34.09it/s]\n",
      "Test loss 0.22641482229890494\n",
      "Test dice 0.773829627824211\n",
      "Current epoch:  6\n",
      "100% 263/263 [02:18<00:00,  2.35it/s]\n",
      "Epoch loss 0.0438117868320117\n",
      "Epoch dice 0.7929272355176309\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 34.21it/s]\n",
      "Test loss 0.21566003766553155\n",
      "Test dice 0.7842414316366377\n",
      "Current epoch:  7\n",
      "100% 263/263 [02:18<00:00,  2.36it/s]\n",
      "Epoch loss 0.04366511327458879\n",
      "Epoch dice 0.7932709054195455\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 31.34it/s]\n",
      "Test loss 0.22044787119174825\n",
      "Test dice 0.779652241174908\n",
      "Current epoch:  8\n",
      "100% 263/263 [02:18<00:00,  2.36it/s]\n",
      "Epoch loss 0.04331272713018461\n",
      "Epoch dice 0.7951851757994588\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 34.52it/s]\n",
      "Test loss 0.21656239731558438\n",
      "Test dice 0.7834925824828741\n",
      "Current epoch:  9\n",
      "100% 263/263 [02:18<00:00,  2.24it/s]\n",
      "Epoch loss 0.04328251007391926\n",
      "Epoch dice 0.794807452301125\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 34.96it/s]\n",
      "Test loss 0.21645117381523396\n",
      "Test dice 0.7835706256170949\n",
      "Current epoch:  10\n",
      "100% 263/263 [02:18<00:00,  2.26it/s]\n",
      "Epoch loss 0.04342608479605881\n",
      "Epoch dice 0.7939656988830257\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 32.32it/s]\n",
      "Test loss 0.21994780918647502\n",
      "Test dice 0.780091027903002\n",
      "Current epoch:  11\n",
      "100% 263/263 [02:21<00:00,  2.38it/s]\n",
      "Epoch loss 0.042679039244416093\n",
      "Epoch dice 0.7982904074610558\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 31.48it/s]\n",
      "Test loss 0.21730922090596166\n",
      "Test dice 0.7827023827589925\n",
      "Current epoch:  12\n",
      "100% 263/263 [02:17<00:00,  2.26it/s]\n",
      "Epoch loss 0.04308603371957409\n",
      "Epoch dice 0.7957242661635031\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 34.27it/s]\n",
      "Test loss 0.21603217412685527\n",
      "Test dice 0.7839518562892922\n",
      "Current epoch:  13\n",
      "100% 263/263 [02:18<00:00,  2.24it/s]\n",
      "Epoch loss 0.04246410401148488\n",
      "Epoch dice 0.7988819371605482\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 32.27it/s]\n",
      "Test loss 0.21693205463475196\n",
      "Test dice 0.7831200699450532\n",
      "Current epoch:  14\n",
      "100% 263/263 [02:18<00:00,  2.39it/s]\n",
      "Epoch loss 0.04238780646269766\n",
      "Epoch dice 0.798491505992201\n",
      "Make test\n",
      "100% 145/145 [00:04<00:00, 34.11it/s]\n",
      "Test loss 0.2195264980710786\n",
      "Test dice 0.7805143107988927\n"
     ]
    }
   ],
   "source": [
    "! python3 \"/content/drive/My Drive/laba/train.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QXk2ADaag3MK"
   },
   "source": [
    "## Загрузка модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eeqn-_pCXRcd"
   },
   "outputs": [],
   "source": [
    "%cd \"/content/drive/My Drive/laba/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1437,
     "status": "ok",
     "timestamp": 1568574687477,
     "user": {
      "displayName": "Софья Федоровна Якушева",
      "photoUrl": "",
      "userId": "11846467870731418335"
     },
     "user_tz": -180
    },
    "id": "r-dZ1JqL8Uio",
    "outputId": "ca5626f6-1527-40bc-d5b3-0e4ce5627065"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SegmenterModel(\n",
       "  (conv1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (conv3): Sequential(\n",
       "    (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (mp2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv5): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (mp3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv7): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (conv8): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (conv9): Sequential(\n",
       "    (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (upsample1): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv10): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (conv11): Sequential(\n",
       "    (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (upsample2): Upsample(scale_factor=2.0, mode=nearest)\n",
       "  (conv12): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (conv13): Sequential(\n",
       "    (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace)\n",
       "  )\n",
       "  (conv14): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from model import SegmenterModel\n",
    "from metrics import *\n",
    "from image_dataset import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as dt\n",
    "from torch.autograd import Variable\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import *\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "segm_model = SegmenterModel()\n",
    "segm_model.load_state_dict(torch.load('/content/drive/My Drive/laba/segm_model1.pth', map_location=torch.device('cpu')))\n",
    "segm_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wCzD6MgMg3MX"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dFakAwsR-FxT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OlJBI-ylWu4r"
   },
   "source": [
    "## Генерация масок для validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6023,
     "status": "ok",
     "timestamp": 1568573643223,
     "user": {
      "displayName": "Софья Федоровна Якушева",
      "photoUrl": "",
      "userId": "11846467870731418335"
     },
     "user_tz": -180
    },
    "id": "bF1V0HJB8Ui7",
    "outputId": "d0e0c668-92bc-4980-86f5-9ec2b4b76cb4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 145/145 [00:04<00:00, 30.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from google.colab.patches import cv2_imshow\n",
    "from skimage.morphology import closing\n",
    "from html import *\n",
    "from utils import *\n",
    "\n",
    "seg_model = segm_model.cuda().eval()\n",
    "test = '/content/drive/My Drive/laba/data/valid/'\n",
    "test_masks = '/content/drive/My Drive/laba/data/valid_mask'\n",
    "\n",
    "rle_masks = []\n",
    "masks = []\n",
    "\n",
    "ds_test = ImageDataset(test, test_masks, augment=False)\n",
    "dl_test = dt.DataLoader(ds_test, shuffle=False, num_workers=4, batch_size=1)\n",
    "dice = 0\n",
    "for iter, (i, t) in enumerate(tqdm(dl_test)):\n",
    "    i = Variable(i, volatile = True)\n",
    "    t = Variable(t, volatile = True)\n",
    "    o = segm_model(i.cuda()).cpu()\n",
    "    \n",
    "    o = (o >= 0.5).type(torch.float)\n",
    "    pict = np.array(o[0,0])\n",
    "    mask = np.array(t[0,0])\n",
    "    dice = (2 * np.sum(pict * mask)) / (np.sum(pict) + np.sum(mask)) \n",
    "    rle_masks.append(encode_rle(mask))\n",
    "    masks.append(mask)\n",
    "    \n",
    "print(len(masks))    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6vUGfE_1NZWH"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "da = pd.DataFrame(masks)\n",
    "da.columns = ['rle_mask']\n",
    "da[\"id\"] = np.arange(1315, 1460)\n",
    "da.to_csv('/content/drive/My Drive/laba/pred_valid_template.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-di33xvNWpTQ"
   },
   "source": [
    "## Генерация HTML-страницы\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 53
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4582,
     "status": "ok",
     "timestamp": 1568574735942,
     "user": {
      "displayName": "Софья Федоровна Якушева",
      "photoUrl": "",
      "userId": "11846467870731418335"
     },
     "user_tz": -180
    },
    "id": "UImdFVm0Rvze",
    "outputId": "04f77963-00dd-41dc-fd75-ad643dda1d30"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:03<00:00, 34.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "seg_model = segm_model.cuda().eval()\n",
    "test = '/content/drive/My Drive/laba/data/test/'\n",
    "\n",
    "seg_model = segm_model.cuda().eval()\n",
    "\n",
    "rle_masks = []\n",
    "masks = []\n",
    "\n",
    "ds_test = OnlyImageDataset(test)\n",
    "dl_test = dt.DataLoader(ds_test, shuffle=False, num_workers=4, batch_size=1)\n",
    "dice = 0\n",
    "for iter, i in enumerate(tqdm(dl_test)):\n",
    "    i = Variable(i, volatile = True)\n",
    "    o = segm_model(i.cuda()).cpu()\n",
    "    \n",
    "    o = (o >= 0.5).type(torch.float)\n",
    "    pict = (255*np.array(o[0,0])).astype(np.uint8)\n",
    "    masks.append(pict)\n",
    "    \n",
    "print(len(masks)) \n",
    "\n",
    "from html import *\n",
    "paths_to_imgs = sorted(glob(\"/content/drive/My Drive/laba/data/test/*\"))\n",
    "pred_masks = masks\n",
    "\n",
    "_ = get_html(paths_to_imgs, pred_masks, path_to_save=\"/content/drive/My Drive/laba/results/example\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UNDF3eSVO_Ja"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fdIZDpGbg3Mn"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HW_5_ObjectSegmentation.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
